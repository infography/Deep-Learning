{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('use_NHPC.csv',header=None,index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = df.values\n",
    "dataset = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_d=[]\n",
    "y_d=[]\n",
    "for i in dataset:\n",
    "    x_d.append(i[1])\n",
    "    y_d.append(i[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_d = np.array(x_d)\n",
    "y_d = np.array(y_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = (df[2].values[:500]).reshape(500,1)\n",
    "x = (x_d[:500]).reshape(500,1)\n",
    "# y= (df[1].values[:500]).reshape(500,1)\n",
    "y = (y_d[:500]).reshape(500,1)\n",
    "# x_t = (df[2].values[500:]).reshape(47,1)\n",
    "x_t = (x_d[500:]).reshape(47,1)\n",
    "# y_t = (df[1].values[500:]).reshape(47,1)\n",
    "y_t = (y_d[500:]).reshape(47,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.reshape(x, (x.shape[0], 1,x.shape[1]))\n",
    "x_test = np.reshape(x_t, (x_t.shape[0], 1,x_t.shape[1]))\n",
    "# y_train = np.reshape(y, (y.shape[0], 1,y.shape[1]))\n",
    "y_train = y\n",
    "y_test = np.reshape(y_t, (y_t.shape[0], 1,y_t.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_train = y.reshape(500,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_test = df[2].values[500:].reshape(47,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_test = df[1].values[500:].reshape(47,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(1,1),stateful=True,batch_size=1))\n",
    "model.add(LSTM(100,return_sequences=False,stateful=True))\n",
    "model.add(Dense(1, activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8s - loss: 0.0131\n",
      "Epoch 2/100\n",
      "6s - loss: 0.0076\n",
      "Epoch 3/100\n",
      "6s - loss: 0.0078\n",
      "Epoch 4/100\n",
      "6s - loss: 0.0075\n",
      "Epoch 5/100\n",
      "6s - loss: 0.0077\n",
      "Epoch 6/100\n",
      "6s - loss: 0.0074\n",
      "Epoch 7/100\n",
      "6s - loss: 0.0084\n",
      "Epoch 8/100\n",
      "6s - loss: 0.0062\n",
      "Epoch 9/100\n",
      "6s - loss: 0.0085\n",
      "Epoch 10/100\n",
      "6s - loss: 0.0054\n",
      "Epoch 11/100\n",
      "6s - loss: 0.0052\n",
      "Epoch 12/100\n",
      "6s - loss: 0.0059\n",
      "Epoch 13/100\n",
      "6s - loss: 0.0046\n",
      "Epoch 14/100\n",
      "6s - loss: 0.0045\n",
      "Epoch 15/100\n",
      "6s - loss: 0.0051\n",
      "Epoch 16/100\n",
      "6s - loss: 0.0055\n",
      "Epoch 17/100\n",
      "6s - loss: 0.0052\n",
      "Epoch 18/100\n",
      "6s - loss: 0.0050\n",
      "Epoch 19/100\n",
      "6s - loss: 0.0051\n",
      "Epoch 20/100\n",
      "6s - loss: 0.0049\n",
      "Epoch 21/100\n",
      "6s - loss: 0.0048\n",
      "Epoch 22/100\n",
      "6s - loss: 0.0048\n",
      "Epoch 23/100\n",
      "6s - loss: 0.0048\n",
      "Epoch 24/100\n",
      "6s - loss: 0.0047\n",
      "Epoch 25/100\n",
      "6s - loss: 0.0047\n",
      "Epoch 26/100\n",
      "6s - loss: 0.0046\n",
      "Epoch 27/100\n",
      "6s - loss: 0.0048\n",
      "Epoch 28/100\n",
      "6s - loss: 0.0044\n",
      "Epoch 29/100\n",
      "6s - loss: 0.0040\n",
      "Epoch 30/100\n",
      "6s - loss: 0.0039\n",
      "Epoch 31/100\n",
      "6s - loss: 0.0036\n",
      "Epoch 32/100\n",
      "6s - loss: 0.0034\n",
      "Epoch 33/100\n",
      "6s - loss: 0.0031\n",
      "Epoch 34/100\n",
      "6s - loss: 0.0030\n",
      "Epoch 35/100\n",
      "6s - loss: 0.0028\n",
      "Epoch 36/100\n",
      "6s - loss: 0.0026\n",
      "Epoch 37/100\n",
      "6s - loss: 0.0026\n",
      "Epoch 38/100\n",
      "6s - loss: 0.0024\n",
      "Epoch 39/100\n",
      "6s - loss: 0.0023\n",
      "Epoch 40/100\n",
      "6s - loss: 0.0022\n",
      "Epoch 41/100\n",
      "6s - loss: 0.0022\n",
      "Epoch 42/100\n",
      "6s - loss: 0.0021\n",
      "Epoch 43/100\n",
      "6s - loss: 0.0019\n",
      "Epoch 44/100\n",
      "7s - loss: 0.0018\n",
      "Epoch 45/100\n",
      "7s - loss: 0.0017\n",
      "Epoch 46/100\n",
      "6s - loss: 0.0016\n",
      "Epoch 47/100\n",
      "6s - loss: 0.0016\n",
      "Epoch 48/100\n",
      "6s - loss: 0.0016\n",
      "Epoch 49/100\n",
      "6s - loss: 0.0016\n",
      "Epoch 50/100\n",
      "6s - loss: 0.0016\n",
      "Epoch 51/100\n",
      "6s - loss: 0.0015\n",
      "Epoch 52/100\n",
      "6s - loss: 0.0015\n",
      "Epoch 53/100\n",
      "6s - loss: 0.0015\n",
      "Epoch 54/100\n",
      "6s - loss: 0.0015\n",
      "Epoch 55/100\n",
      "7s - loss: 0.0015\n",
      "Epoch 56/100\n",
      "8s - loss: 0.0015\n",
      "Epoch 57/100\n",
      "7s - loss: 0.0014\n",
      "Epoch 58/100\n",
      "7s - loss: 0.0015\n",
      "Epoch 59/100\n",
      "6s - loss: 0.0015\n",
      "Epoch 60/100\n",
      "7s - loss: 0.0015\n",
      "Epoch 61/100\n",
      "7s - loss: 0.0014\n",
      "Epoch 62/100\n",
      "7s - loss: 0.0015\n",
      "Epoch 63/100\n",
      "6s - loss: 0.0015\n",
      "Epoch 64/100\n",
      "6s - loss: 0.0016\n",
      "Epoch 65/100\n",
      "6s - loss: 0.0016\n",
      "Epoch 66/100\n",
      "6s - loss: 0.0015\n",
      "Epoch 67/100\n",
      "6s - loss: 0.0016\n",
      "Epoch 68/100\n",
      "6s - loss: 0.0021\n",
      "Epoch 69/100\n",
      "6s - loss: 0.0036\n",
      "Epoch 70/100\n",
      "6s - loss: 0.0022\n",
      "Epoch 71/100\n",
      "6s - loss: 0.0018\n",
      "Epoch 72/100\n",
      "6s - loss: 0.0020\n",
      "Epoch 73/100\n",
      "6s - loss: 0.0023\n",
      "Epoch 74/100\n",
      "6s - loss: 0.0027\n",
      "Epoch 75/100\n",
      "6s - loss: 0.0033\n",
      "Epoch 76/100\n",
      "7s - loss: 0.0042\n",
      "Epoch 77/100\n",
      "7s - loss: 0.0026\n",
      "Epoch 78/100\n",
      "7s - loss: 0.0023\n",
      "Epoch 79/100\n",
      "7s - loss: 0.0024\n",
      "Epoch 80/100\n",
      "7s - loss: 0.0022\n",
      "Epoch 81/100\n",
      "6s - loss: 0.0022\n",
      "Epoch 82/100\n",
      "6s - loss: 0.0020\n",
      "Epoch 83/100\n",
      "6s - loss: 0.0016\n",
      "Epoch 84/100\n",
      "6s - loss: 0.0016\n",
      "Epoch 85/100\n",
      "7s - loss: 0.0016\n",
      "Epoch 86/100\n",
      "7s - loss: 0.0017\n",
      "Epoch 87/100\n",
      "6s - loss: 0.0018\n",
      "Epoch 88/100\n",
      "7s - loss: 0.0019\n",
      "Epoch 89/100\n",
      "7s - loss: 0.0024\n",
      "Epoch 90/100\n",
      "8s - loss: 0.0024\n",
      "Epoch 91/100\n",
      "7s - loss: 0.0044\n",
      "Epoch 92/100\n",
      "7s - loss: 0.0024\n",
      "Epoch 93/100\n",
      "6s - loss: 0.0028\n",
      "Epoch 94/100\n",
      "6s - loss: 0.0027\n",
      "Epoch 95/100\n",
      "6s - loss: 0.0023\n",
      "Epoch 96/100\n",
      "7s - loss: 0.0028\n",
      "Epoch 97/100\n",
      "7s - loss: 0.0027\n",
      "Epoch 98/100\n",
      "7s - loss: 0.0020\n",
      "Epoch 99/100\n",
      "6s - loss: 0.0018\n",
      "Epoch 100/100\n",
      "6s - loss: 0.0021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11cdb9650>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,epochs=100,verbose=2,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(x_test,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.43309841]\n",
      " [ 0.45526093]\n",
      " [ 0.45759961]\n",
      " [ 0.42275169]\n",
      " [ 0.46540916]\n",
      " [ 0.41832125]\n",
      " [ 0.44514912]\n",
      " [ 0.41613474]\n",
      " [ 0.43334144]\n",
      " [ 0.40292382]\n",
      " [ 0.39680421]\n",
      " [ 0.32994652]\n",
      " [ 0.36953735]\n",
      " [ 0.34224612]\n",
      " [ 0.34181315]\n",
      " [ 0.32076353]\n",
      " [ 0.35191995]\n",
      " [ 0.31360221]\n",
      " [ 0.34229064]\n",
      " [ 0.30168515]\n",
      " [ 0.31941891]\n",
      " [ 0.28814679]\n",
      " [ 0.32230553]\n",
      " [ 0.26411864]\n",
      " [ 0.31178877]\n",
      " [ 0.33533019]\n",
      " [ 0.37641549]\n",
      " [ 0.3232469 ]\n",
      " [ 0.35658851]\n",
      " [ 0.35001364]\n",
      " [ 0.33997962]\n",
      " [ 0.32224753]\n",
      " [ 0.31815034]\n",
      " [ 0.30078182]\n",
      " [ 0.30374739]\n",
      " [ 0.31690165]\n",
      " [ 0.31250161]\n",
      " [ 0.3065002 ]\n",
      " [ 0.33042797]\n",
      " [ 0.31294128]\n",
      " [ 0.29925254]\n",
      " [ 0.30371031]\n",
      " [ 0.30194271]\n",
      " [ 0.27592063]\n",
      " [ 0.31307665]\n",
      " [ 0.31555566]\n",
      " [ 0.30868763]]\n"
     ]
    }
   ],
   "source": [
    "print prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>124.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>123.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>120.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>124.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>123.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>125.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>124.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-01-13</td>\n",
       "      <td>125.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-01-14</td>\n",
       "      <td>126.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>126.0</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2015-01-19</td>\n",
       "      <td>128.0</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2015-01-20</td>\n",
       "      <td>125.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015-01-22</td>\n",
       "      <td>125.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>126.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-01-26</td>\n",
       "      <td>125.0</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015-01-27</td>\n",
       "      <td>128.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>127.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2015-01-29</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2015-02-02</td>\n",
       "      <td>125.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2015-02-03</td>\n",
       "      <td>126.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2015-02-04</td>\n",
       "      <td>127.0</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2015-02-05</td>\n",
       "      <td>125.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2015-02-08</td>\n",
       "      <td>127.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015-02-09</td>\n",
       "      <td>125.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2015-02-10</td>\n",
       "      <td>124.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2015-02-11</td>\n",
       "      <td>125.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2015-02-12</td>\n",
       "      <td>124.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2015-02-15</td>\n",
       "      <td>123.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2015-02-16</td>\n",
       "      <td>125.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>143.0</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>140.0</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>2017-05-02</td>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>2017-05-03</td>\n",
       "      <td>138.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>140.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>133.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>2017-05-08</td>\n",
       "      <td>138.0</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>2017-05-09</td>\n",
       "      <td>143.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>2017-05-11</td>\n",
       "      <td>146.0</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>2017-05-15</td>\n",
       "      <td>141.0</td>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>2017-05-16</td>\n",
       "      <td>145.0</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>2017-05-17</td>\n",
       "      <td>146.0</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>2017-05-18</td>\n",
       "      <td>144.0</td>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>143.0</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>2017-05-22</td>\n",
       "      <td>141.0</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>140.0</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>2017-05-24</td>\n",
       "      <td>139.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>142.0</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>2017-05-30</td>\n",
       "      <td>140.0</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>142.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>2017-06-04</td>\n",
       "      <td>140.0</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>2017-06-05</td>\n",
       "      <td>138.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>2017-06-06</td>\n",
       "      <td>139.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>2017-06-07</td>\n",
       "      <td>138.0</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>2017-06-08</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>2017-06-11</td>\n",
       "      <td>139.0</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>2017-06-12</td>\n",
       "      <td>139.0</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>2017-06-13</td>\n",
       "      <td>138.0</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>2017-06-14</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>547 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0      1      2\n",
       "0    2015-01-04  124.0  123.0\n",
       "1    2015-01-05  123.0  124.0\n",
       "2    2015-01-06  120.0  123.0\n",
       "3    2015-01-07  124.0  120.0\n",
       "4    2015-01-08  123.0  124.0\n",
       "5    2015-01-11  125.0  123.0\n",
       "6    2015-01-12  124.0  125.0\n",
       "7    2015-01-13  125.0  124.0\n",
       "8    2015-01-14  126.0  125.0\n",
       "9    2015-01-18  126.0  126.0\n",
       "10   2015-01-19  128.0  126.0\n",
       "11   2015-01-20  125.0  128.0\n",
       "12   2015-01-22  125.0  125.0\n",
       "13   2015-01-25  126.0  125.0\n",
       "14   2015-01-26  125.0  126.0\n",
       "15   2015-01-27  128.0  125.0\n",
       "16   2015-01-28  127.0  128.0\n",
       "17   2015-01-29  127.0  127.0\n",
       "18   2015-02-01  127.0  127.0\n",
       "19   2015-02-02  125.0  127.0\n",
       "20   2015-02-03  126.0  125.0\n",
       "21   2015-02-04  127.0  126.0\n",
       "22   2015-02-05  125.0  127.0\n",
       "23   2015-02-08  127.0  125.0\n",
       "24   2015-02-09  125.0  127.0\n",
       "25   2015-02-10  124.0  125.0\n",
       "26   2015-02-11  125.0  124.0\n",
       "27   2015-02-12  124.0  125.0\n",
       "28   2015-02-15  123.0  124.0\n",
       "29   2015-02-16  125.0  123.0\n",
       "..          ...    ...    ...\n",
       "517  2017-04-27  143.0  142.0\n",
       "518  2017-04-30  140.0  143.0\n",
       "519  2017-05-02  140.0  140.0\n",
       "520  2017-05-03  138.0  140.0\n",
       "521  2017-05-04  140.0  138.0\n",
       "522  2017-05-07  133.0  140.0\n",
       "523  2017-05-08  138.0  133.0\n",
       "524  2017-05-09  143.0  138.0\n",
       "525  2017-05-11  146.0  143.0\n",
       "526  2017-05-15  141.0  146.0\n",
       "527  2017-05-16  145.0  141.0\n",
       "528  2017-05-17  146.0  145.0\n",
       "529  2017-05-18  144.0  146.0\n",
       "530  2017-05-21  143.0  144.0\n",
       "531  2017-05-22  141.0  143.0\n",
       "532  2017-05-23  140.0  141.0\n",
       "533  2017-05-24  139.0  140.0\n",
       "534  2017-05-28  142.0  139.0\n",
       "535  2017-05-30  140.0  142.0\n",
       "536  2017-05-31  140.0  140.0\n",
       "537  2017-06-01  142.0  140.0\n",
       "538  2017-06-04  140.0  142.0\n",
       "539  2017-06-05  138.0  140.0\n",
       "540  2017-06-06  139.0  138.0\n",
       "541  2017-06-07  138.0  139.0\n",
       "542  2017-06-08  135.0  138.0\n",
       "543  2017-06-11  139.0  135.0\n",
       "544  2017-06-12  139.0  139.0\n",
       "545  2017-06-13  138.0  139.0\n",
       "546  2017-06-14  135.0  138.0\n",
       "\n",
       "[547 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rmse = np.sqrt(mean_squared_error(prediction,y_test))\n",
    "prediction = prediction.reshape(47,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-369-c2b3033a3a16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/metrics/regression.pyc\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \"\"\"\n\u001b[1;32m    230\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 231\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    232\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n\u001b[1;32m    233\u001b[0m                                weights=sample_weight)\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/metrics/regression.pyc\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0;32m--> 405\u001b[0;31m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = prediction.reshape(-1,47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(p.reshape(47,1),(y_test.reshape(-1,47).reshape(47,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.2507358966\n"
     ]
    }
   ],
   "source": [
    "print rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
